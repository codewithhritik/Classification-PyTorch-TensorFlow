{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install -U ucimlrepo"
      ],
      "metadata": {
        "id": "c5AgNFa-9Mqx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "YHHCSSvoLwu-",
        "outputId": "de2dc643-c1bc-4b93-86a5-c3ddc50b1827"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ucimlrepo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-232d07cf8ae6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucimlrepo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# Data (as pandas dataframes)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets\n",
        "\n",
        "# Preprocess data\n",
        "means = X.mean()\n",
        "X = X.fillna(means)\n",
        "X = pd.get_dummies(X)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train.astype(np.float32))\n",
        "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).view(-1, 1)\n",
        "X_val_tensor = torch.tensor(X_val.astype(np.float32))\n",
        "y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test.astype(np.float32))\n",
        "y_test_tensor = torch.tensor(y_test.values.astype(np.float32)).view(-1, 1)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "mrnU1_FuL0z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class DiabetesPredictor(nn.Module):\n",
        "    def __init__(self, input_features):\n",
        "        super(DiabetesPredictor, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "input_features = X_train.shape[1]\n",
        "model = DiabetesPredictor(input_features)"
      ],
      "metadata": {
        "id": "DpJMW50lL7rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 40\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss_accum = []  # List to store losses of each batch\n",
        "\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_accum.append(loss.item())  # Append the loss of the current batch\n",
        "\n",
        "    # Compute average training loss for the epoch and store it\n",
        "    epoch_train_loss = np.mean(train_loss_accum)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # Compute validation loss for the epoch and store it\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_accum = []  # List to store validation losses\n",
        "        for data, labels in val_loader:\n",
        "            outputs = model(data)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_loss_accum.append(val_loss.item())\n",
        "\n",
        "        epoch_val_loss = np.mean(val_loss_accum)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}')"
      ],
      "metadata": {
        "id": "LazUca5zMCiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loop\n",
        "test_losses = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_index, (batch_x, batch_y) in enumerate(test_loader):\n",
        "        if batch_index % 20 == 0:  # Check if the current batch index is a multiple of 20\n",
        "            preds = model(batch_x)  # Get predictions\n",
        "            loss = criterion(preds, batch_y)  # Compute loss\n",
        "            test_losses.append(loss.item())"
      ],
      "metadata": {
        "id": "Hru895CJMIUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training and validation loss vs epochs\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss vs Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "myjlz4l_OkFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting test loss for every 20th batch\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(0, len(test_losses) * 20, 20), test_losses, label='Test Loss per 20th Batch')\n",
        "plt.title('Test Loss for Every 20th Batch')\n",
        "plt.xlabel('Batch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GMVA0XaOmFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "# Compute ROC curve and ROC area\n",
        "with torch.no_grad():\n",
        "    y_pred_probs = model(X_test_tensor).detach().numpy()\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Compute Precision-Recall curve and area\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_probs)\n",
        "pr_auc = average_precision_score(y_test, y_pred_probs)\n",
        "\n",
        "# Plotting the ROC Curve and Precision-Recall Curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# ROC Curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Precision-Recall Curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plotting histogram of predicted probabilities\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(y_pred_probs, bins=50, color='blue', alpha=0.7, label='Predicted probabilities')\n",
        "plt.title('Histogram of predicted probabilities')\n",
        "plt.xlabel('Predicted probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TZk3CEvZZ29J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}